{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNS90nwSXMcJiqBSsMfbC4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quantam665/-AI-Powered-HIV-Drug-Discovery-System/blob/main/Drug_Discovery_and_Development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ik0_L5oPRZYd",
        "outputId": "dea50c78-7fd4-4033-ff2b-3ecbae222843"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª Dataset Loaded: (41127, 3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[07:01:40] WARNING: not removing hydrogen atom without neighbors\n",
            "[07:01:40] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš–ï¸ Class Weights: {0: np.float64(0.5180444024563061), 1: np.float64(14.354712041884817)}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.6175 - loss: 0.8558 - val_accuracy: 0.8095 - val_loss: 0.5582\n",
            "Epoch 2/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.7902 - loss: 0.4391 - val_accuracy: 0.7086 - val_loss: 0.5702\n",
            "Epoch 3/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.8377 - loss: 0.3161 - val_accuracy: 0.8833 - val_loss: 0.3527\n",
            "Epoch 4/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9014 - loss: 0.2430 - val_accuracy: 0.9031 - val_loss: 0.2797\n",
            "Epoch 5/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9269 - loss: 0.1677 - val_accuracy: 0.8508 - val_loss: 0.3997\n",
            "Epoch 6/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9286 - loss: 0.1597 - val_accuracy: 0.9012 - val_loss: 0.2925\n",
            "Epoch 7/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 21ms/step - accuracy: 0.9463 - loss: 0.1271 - val_accuracy: 0.9164 - val_loss: 0.2776\n",
            "Epoch 8/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9536 - loss: 0.1225 - val_accuracy: 0.9137 - val_loss: 0.2977\n",
            "Epoch 9/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9533 - loss: 0.1164 - val_accuracy: 0.9283 - val_loss: 0.2698\n",
            "Epoch 10/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9563 - loss: 0.1257 - val_accuracy: 0.9012 - val_loss: 0.3161\n",
            "Epoch 11/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9483 - loss: 0.1337 - val_accuracy: 0.9116 - val_loss: 0.3089\n",
            "Epoch 12/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9622 - loss: 0.0991 - val_accuracy: 0.8864 - val_loss: 0.3890\n",
            "Epoch 13/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9587 - loss: 0.1043 - val_accuracy: 0.9161 - val_loss: 0.3135\n",
            "Epoch 14/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9590 - loss: 0.1110 - val_accuracy: 0.8973 - val_loss: 0.3427\n",
            "Epoch 15/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9605 - loss: 0.1146 - val_accuracy: 0.8973 - val_loss: 0.3909\n",
            "Epoch 16/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9565 - loss: 0.1296 - val_accuracy: 0.9407 - val_loss: 0.3118\n",
            "Epoch 17/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9643 - loss: 0.1146 - val_accuracy: 0.9292 - val_loss: 0.3473\n",
            "Epoch 18/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9581 - loss: 0.1277 - val_accuracy: 0.9459 - val_loss: 0.3183\n",
            "Epoch 19/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9733 - loss: 0.0886 - val_accuracy: 0.9180 - val_loss: 0.4344\n",
            "Epoch 20/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9647 - loss: 0.1106 - val_accuracy: 0.8903 - val_loss: 0.4303\n",
            "Epoch 21/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9627 - loss: 0.1131 - val_accuracy: 0.9119 - val_loss: 0.3937\n",
            "Epoch 22/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9714 - loss: 0.0927 - val_accuracy: 0.9307 - val_loss: 0.3553\n",
            "Epoch 23/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9751 - loss: 0.0760 - val_accuracy: 0.9249 - val_loss: 0.3765\n",
            "Epoch 24/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9686 - loss: 0.0849 - val_accuracy: 0.9417 - val_loss: 0.3283\n",
            "Epoch 25/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9758 - loss: 0.0720 - val_accuracy: 0.9213 - val_loss: 0.4152\n",
            "Epoch 26/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9673 - loss: 0.1148 - val_accuracy: 0.9140 - val_loss: 0.3792\n",
            "Epoch 27/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9684 - loss: 0.1028 - val_accuracy: 0.8818 - val_loss: 0.4791\n",
            "Epoch 28/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9711 - loss: 0.0883 - val_accuracy: 0.9341 - val_loss: 0.3861\n",
            "Epoch 29/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9759 - loss: 0.0877 - val_accuracy: 0.9429 - val_loss: 0.3687\n",
            "Epoch 30/30\n",
            "\u001b[1m463/463\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9819 - loss: 0.0756 - val_accuracy: 0.9322 - val_loss: 0.4391\n",
            "\u001b[1m258/258\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "ğŸ§ª Test Accuracy: 0.9246\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://453415a5be9d7d5ea8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://453415a5be9d7d5ea8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# âœ… STEP 1: Install everything needed\n",
        "!pip install -q rdkit-pypi gradio scikit-learn tensorflow pandas matplotlib seaborn\n",
        "\n",
        "# âœ… STEP 2: Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit.Chem import Draw\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# âœ… STEP 3: Load the dataset (already uploaded as /content/HIV.csv)\n",
        "df = pd.read_csv(\"/content/HIV.csv\")\n",
        "print(\"ğŸ§ª Dataset Loaded:\", df.shape)\n",
        "\n",
        "# âœ… STEP 4: Convert SMILES to ECFP4 Fingerprints\n",
        "def smiles_to_ecfp(smiles, radius=2, n_bits=2048):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol:\n",
        "        return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits))\n",
        "    else:\n",
        "        return np.zeros(n_bits)\n",
        "\n",
        "df = df.dropna()\n",
        "X = np.array([smiles_to_ecfp(s) for s in df['smiles']])\n",
        "y = df['HIV_active'].values\n",
        "\n",
        "# âœ… STEP 5: Train-test split and scaling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# âœ… STEP 6: Handle class imbalance using class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "cw = {0: class_weights[0], 1: class_weights[1]}\n",
        "print(\"âš–ï¸ Class Weights:\", cw)\n",
        "\n",
        "# âœ… STEP 7: Build the deep learning model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# âœ… STEP 8: Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=30, batch_size=64, class_weight=cw, verbose=1, validation_split=0.1)\n",
        "\n",
        "# âœ… STEP 9: Evaluate model on test data\n",
        "test_preds = model.predict(X_test_scaled).flatten()\n",
        "test_classes = (test_preds > 0.5).astype(int)\n",
        "acc = accuracy_score(y_test, test_classes)\n",
        "print(f\"ğŸ§ª Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "# âœ… STEP 10: Define Gradio Dashboard\n",
        "def predict_from_smiles(smiles_input):\n",
        "    mol = Chem.MolFromSmiles(smiles_input)\n",
        "    if not mol:\n",
        "        return \"Invalid SMILES\", \"-\", \"<b style='color:red;'>Invalid SMILES structure</b>\"\n",
        "\n",
        "    fp = smiles_to_ecfp(smiles_input)\n",
        "    fp_scaled = scaler.transform([fp])\n",
        "    prob = float(model.predict(fp_scaled)[0])\n",
        "    pred = \"HIV Active\" if prob > 0.5 else \"Not Active\"\n",
        "\n",
        "    img = Draw.MolToImage(mol, size=(250,250))\n",
        "    buffer = io.BytesIO()\n",
        "    img.save(buffer, format='PNG')\n",
        "    img_b64 = base64.b64encode(buffer.getvalue()).decode()\n",
        "    html_img = f'<img src=\"data:image/png;base64,{img_b64}\"/>'\n",
        "\n",
        "    return pred, f\"{prob:.2f}\", html_img\n",
        "\n",
        "# âœ… STEP 11: Launch Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_from_smiles,\n",
        "    inputs=gr.Textbox(label=\"Enter SMILES String\"),\n",
        "    outputs=[\n",
        "        gr.Label(label=\"Prediction\"),\n",
        "        gr.Label(label=\"Confidence Score\"),\n",
        "        gr.HTML(label=\"Molecule Structure\")\n",
        "    ],\n",
        "    title=\"ğŸ§  AI-Powered HIV Activity Prediction\",\n",
        "    description=\"Enter a moleculeâ€™s SMILES string to predict if it is HIV Active. Built using Deep Learning + RDKit + ECFP4.\",\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ]
    }
  ]
}